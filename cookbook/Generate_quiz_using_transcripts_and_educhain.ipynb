{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Unlock the Power of Educhain: Create Quizzes and Questions from Your Favorite Videos Using Transcripts and More! ğŸš€"
      ],
      "metadata": {
        "id": "_OUfeQ5bOSse"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1jOW09N50DDG4tJ5PZOIjWGlW3_AiMDJu?usp=sharing)\n"
      ],
      "metadata": {
        "id": "sGFNUPbb6cVP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5bVl67uh_pW",
        "outputId": "4e1faf9a-3c78-422d-d3d8-391cc63980ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting educhain\n",
            "  Downloading educhain-0.3.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (from educhain) (0.3.7)\n",
            "Collecting langchain-community (from educhain)\n",
            "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-openai (from educhain)\n",
            "  Downloading langchain_openai-0.2.9-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from educhain) (1.54.4)\n",
            "Collecting python-dotenv (from educhain)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from educhain) (2.2.2)\n",
            "Collecting reportlab (from educhain)\n",
            "  Downloading reportlab-4.2.5-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting PyPDF2 (from educhain)\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from educhain) (4.12.3)\n",
            "Collecting youtube-transcript-api (from educhain)\n",
            "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from educhain) (2.9.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from educhain) (2.32.3)\n",
            "Collecting chromadb (from educhain)\n",
            "  Downloading chromadb-0.5.20-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->educhain) (2.6)\n",
            "Collecting build>=1.0.3 (from chromadb->educhain)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb->educhain)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb->educhain)\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb->educhain)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb->educhain) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb->educhain)\n",
            "  Downloading posthog-3.7.2-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->educhain) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb->educhain)\n",
            "  Downloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->educhain) (1.28.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->educhain) (1.28.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb->educhain) (0.20.3)\n",
            "Collecting pypika>=0.48.9 (from chromadb->educhain)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->educhain) (4.66.6)\n",
            "Collecting overrides>=7.3.1 (from chromadb->educhain)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb->educhain) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->educhain) (1.67.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb->educhain)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->educhain) (0.13.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb->educhain)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb->educhain) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->educhain) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb->educhain)\n",
            "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb->educhain) (3.10.11)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->educhain) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->educhain) (13.9.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->educhain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->educhain) (2.23.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->educhain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->educhain) (3.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->educhain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain->educhain) (0.3.18)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain->educhain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain->educhain) (0.1.143)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->educhain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->educhain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->educhain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->educhain) (2024.8.30)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain->educhain)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community->educhain)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community->educhain)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community->educhain)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai->educhain)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai->educhain) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai->educhain) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai->educhain) (0.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai->educhain) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->educhain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->educhain) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->educhain) (2024.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab->educhain) (11.0.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from reportlab->educhain) (5.2.0)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api->educhain) (0.7.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->educhain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->educhain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->educhain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->educhain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->educhain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->educhain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->educhain) (1.17.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->educhain) (1.2.2)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb->educhain) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb->educhain)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb->educhain) (2.1.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->educhain)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->educhain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb->educhain)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb->educhain) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb->educhain) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->educhain) (1.16.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->educhain) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->educhain) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->educhain) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->educhain) (3.2.2)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb->educhain)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain->educhain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain->educhain) (1.0.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb->educhain)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb->educhain) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb->educhain) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb->educhain) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb->educhain) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb->educhain) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb->educhain)\n",
            "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain) (1.16.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_api-1.28.2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb->educhain)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb->educhain)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb->educhain) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb->educhain) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->educhain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai->educhain) (2024.9.11)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb->educhain) (0.26.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb->educhain) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb->educhain) (1.5.4)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb->educhain)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb->educhain)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb->educhain)\n",
            "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb->educhain)\n",
            "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->educhain) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->educhain) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->educhain) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb->educhain) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb->educhain) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->educhain) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain->educhain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->educhain) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->educhain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb->educhain)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb->educhain) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->educhain) (0.6.1)\n",
            "Downloading educhain-0.3.2-py3-none-any.whl (25 kB)\n",
            "Downloading chromadb-0.5.20-py3-none-any.whl (617 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m617.9/617.9 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.9-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading reportlab-4.2.5-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m159.2/159.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.28.2-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.49b2-py3-none-any.whl (6.9 kB)\n",
            "Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m118.8/118.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.7.2-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=bff652c54a5649aa208d68dfd71183dd5075d25ab6432f7eb664892160cc5889\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, websockets, uvloop, uvicorn, SQLAlchemy, reportlab, python-dotenv, pyproject_hooks, PyPDF2, protobuf, overrides, opentelemetry-util-http, mypy-extensions, mmh3, marshmallow, humanfriendly, httpx-sse, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, youtube-transcript-api, watchfiles, typing-inspect, tiktoken, starlette, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, build, pydantic-settings, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, dataclasses-json, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langchain-openai, opentelemetry-instrumentation-fastapi, langchain-community, chromadb, educhain\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.28.1\n",
            "    Uninstalling opentelemetry-api-1.28.1:\n",
            "      Successfully uninstalled opentelemetry-api-1.28.1\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.49b1\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.49b1:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.49b1\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.28.1\n",
            "    Uninstalling opentelemetry-sdk-1.28.1:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.28.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyPDF2-3.0.1 SQLAlchemy-2.0.35 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.20 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.9 educhain-0.3.2 fastapi-0.115.5 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 kubernetes-31.0.0 langchain-community-0.3.7 langchain-openai-0.2.9 marshmallow-3.23.1 mmh3-5.0.1 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.20.0 opentelemetry-api-1.28.2 opentelemetry-exporter-otlp-proto-common-1.28.2 opentelemetry-exporter-otlp-proto-grpc-1.28.2 opentelemetry-instrumentation-0.49b2 opentelemetry-instrumentation-asgi-0.49b2 opentelemetry-instrumentation-fastapi-0.49b2 opentelemetry-proto-1.28.2 opentelemetry-sdk-1.28.2 opentelemetry-semantic-conventions-0.49b2 opentelemetry-util-http-0.49b2 overrides-7.7.0 posthog-3.7.2 protobuf-5.28.3 pydantic-settings-2.6.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 reportlab-4.2.5 starlette-0.41.3 tiktoken-0.8.0 typing-inspect-0.9.0 uvicorn-0.32.0 uvloop-0.21.0 watchfiles-0.24.0 websockets-14.1 youtube-transcript-api-0.6.3\n"
          ]
        }
      ],
      "source": [
        "!pip install educhain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n"
      ],
      "metadata": {
        "id": "Cyngt16kiHHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add transcript"
      ],
      "metadata": {
        "id": "IYMf6ptgqbp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"0:01 Hi, everyone. Welcome. In this video, I'm going to talk about LangGraph. So LangGraph is a framework, agentic framework by LangChain.\n",
        "0:10 So it is very similar to LangChain in many ways, but this is specifically created to create agents. So we are going to do the same thing, uh, we are going to create the same react agent, but this time we are going to use LangGraph.\n",
        "0:24 LangGraph is specifically useful when you want to create very complicated agents. First, let us learn about what LANGRAF is and then I'll tell you how architecture of React diagram works and then we will look into some code examples as well.\n",
        "0:40 First of all, let us just try to understand what LANGRAF is. LANGRAF is a framework of LANGChain ecosystem. So LANGChain has a lot of their own frameworks like Lancers, LANGsmith, LANGRAF, so on and so forth.\n",
        "0:54 So these are one of the many frameworks but Langraff is specifically created for creating complex agentic systems. So whenever you are creating agents, you're using Langshin, you're following a linear structure.\n",
        "1:08 So chain is a linear structure where you're sending a prompt that is going to a model, then it's going to a parser, so on and so forth.\n",
        "1:17 Langraff actually follows a cyclic structure rather than the linear structure and change. So, what are the few main components? The main components of lag graph are stateful graphs.\n",
        "1:29 So, you can actually create different nodes in your graph which can store certain information and that information can be changed upon certain foundations.\n",
        "1:39 And instead of traditional linear change, we will use cycles where the agent can loop back to a particular node as many times as it wants until the problem is solved.\n",
        "1:50 So, let me explain with an example. So let's say we are creating a very simple react agent. Let's say in the same question that we asked, what is the, what is two times age of Sharuka, right?\n",
        "2:03 Two times age of Sharuka, that's the question. So this is the question that we are going to ask the agent.\n",
        "2:16 So when Then this goes to the agent, agent has to use tools for two times. So in this case, let's say we have a search tool and we have a calculator tool.\n",
        "2:26 In the first case, the agent will go use the search tool to fetch the age. So it will have the age ready with it.\n",
        "2:35 Now it will decide that it will have to use the calculator agent. Then it will go back, use the calculator agent and fetch the answer.\n",
        "2:42 it. Once it has fetched the answer, we can define an end condition where it can go and end. So this is how you can create a simple react agent using Landgraph.\n",
        "2:53 And now let me show you how you can do that using code. Generally, coding with Landgraph is slightly more complicated compared to Langshin or other frameworks.\n",
        "3:04 But for standard frameworks like create, they have pre-built templates. So that will allow us to create agents within few lines of code.\n",
        "3:12 So, let me show you how that is done. The first step is to install all the necessary dependencies. So, once that is done, you can just save your open API key and I'll show you two examples for it.\n",
        "3:26 One is a simple example with two tools and in the second example, I will create some custom tools and I'll show you how you can create react agents with multiple tools as well.\n",
        "3:38 For the first example, I'm going to use the same tools as we have used before. So we'll be using two tools.\n",
        "3:45 So one will be a search tool and one will be a calculated tool. So this is the search tool from DuckDuckGo and we have created a function called Multiply and this is the function that we have created which takes into integers and spits out the multiplied answer of them.\n",
        "4:06 The way you define tools is very simple you can just import tool module from langchen core and whenever you do whenever you write a function you just need to mention a decorator saying that at tool so it's automatically we converted it into a tool so that is how simple it is to create tools using this\n",
        "4:25 . Just write a function and mention a decorator so we have created two tools and now let me create a react agent using langgraph.\n",
        "4:33 For this we are going to choose a pre-built template from langgraph so since react agent is very useful and most widely used so they have created a pre-built template that you can use directly.\n",
        "4:47 So I'm just importing create react agent and I'm going to use GPT4 mini model. And the tools are multiply and search tool.\n",
        "4:58 And now I'm going to create a graph. So let me run this. And you can visualize the graph as well.\n",
        "5:05 Since we are using the standard react agent, the graph will remain same, irrespective of what tools you have mentioned. So let's say in our case, the tools has two tools.\n",
        "5:16 So let's say if you have 10 tools here, this will have 10 tools, but the diagram won't change much in this case.\n",
        "5:25 I'm going to run a Langerast with the same prompt that we used before, and I'm going to ask what is 5 times the current age of Shahrukh Khan.\n",
        "5:34 So it has to do two searches. First, it'll have to do a Google search to fetch the current age. And in the second stage, it'll have to do a multiplication.\n",
        "5:42 So let us see the process that it has followed. and you can also note with Langer if it is very easy to see the thought process when you come back to Langer.\n",
        "5:54 The first step, this is the question that human ask that we asked. So what is five times the current age of Sharuka and then AI decided that it will have to use a tool called Doug Doug go and the query that it is asking Doug Doug go is what is the current age of Sharuka And it is fetching these all results\n",
        "6:13 from the internet and then it is fetching the current age which is 58 and then it is doing a multiplication tool and then it is giving us the answer.\n",
        "6:24 So you see that there is a multi step reasoning happening within the agent where it is going step by step.\n",
        "6:32 So that is great. So now let me show you a little more complicated example where instead of one tool we have three tools and I have taken all math tools and I will also show you the thought process as to how that is working.\n",
        "6:47 There are three tools, so one is the multiply tool as we have seen before. Now we also have a square root tool and we also have a power tool raised to the exponent tool.\n",
        "6:58 So now we have three tools, multiply, square root and power. In the next step, let us just create an agent with all the three tools and this is the simple structure that you need to follow from this.\n",
        "7:13 And you can display it, it will give you the same diagram anyway. Now the question goes something like this, what is the square root of 4 raised to the power of 10 multiplied by 5.\n",
        "7:27 So let us see if it is giving us a correct answer or not. This is the output that we got, this is the human message that we have given and the agent has break down that particular problem into three different parts and then we can see the step by step calculation and then we arrive at the sensor which\n",
        "7:47 seems to be correct. And you can go and run it for different use cases and you can cross verify if it is working correctly or not.\n",
        "7:55 So this is this is how you can create a simple react agent using land graph in the next video We will learn more about different agent frameworks and we will also do a deep dive into true area\"\"\""
      ],
      "metadata": {
        "id": "I-XwWuXfjZGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Educhain"
      ],
      "metadata": {
        "id": "Fw8IHXQEOgfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from educhain import Educhain\n",
        "\n",
        "client = Educhain()\n",
        "\n",
        "ques = client.qna_engine.generate_questions_from_data(source = text, num = 20, custom_instructions=\"Refer the transcript as things taught and create MCQ's on the same dont ask questions about the docuemnt. Make sure the questions are such that they cover all topics and also after the quiz the student will have a clear understanding of the topic\", source_type=\"text\")"
      ],
      "metadata": {
        "id": "AuxHWRMEiVQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Viola!!\n"
      ],
      "metadata": {
        "id": "ulJymA3xOjVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ques.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWxjqJspiwFr",
        "outputId": "ad5d27d9-abc5-477d-f43a-3b07392ffc68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1:\n",
            "Question: What is LangGraph specifically designed for?\n",
            "Options:\n",
            "  A. Creating simple websites.\n",
            "  B. Creating complex agentic systems.\n",
            "  C. Managing databases.\n",
            "  D. Developing mobile applications.\n",
            "\n",
            "Correct Answer: Creating complex agentic systems.\n",
            "\n",
            "Question 2:\n",
            "Question: How does LangGraph differ from LangChain?\n",
            "Options:\n",
            "  A. LangGraph is for mobile applications.\n",
            "  B. LangGraph follows a cyclic structure while LangChain follows a linear structure.\n",
            "  C. LangChain is older than LangGraph.\n",
            "  D. LangChain is only for data visualization.\n",
            "\n",
            "Correct Answer: LangGraph follows a cyclic structure while LangChain follows a linear structure.\n",
            "\n",
            "Question 3:\n",
            "Question: What are the main components of LangGraph?\n",
            "Options:\n",
            "  A. Stateful graphs.\n",
            "  B. Static models.\n",
            "  C. Linear chains.\n",
            "  D. Data tables.\n",
            "\n",
            "Correct Answer: Stateful graphs.\n",
            "\n",
            "Question 4:\n",
            "Question: In LangGraph, what does a node in the graph do?\n",
            "Options:\n",
            "  A. Stores static data.\n",
            "  B. Stores certain information that can change based on conditions.\n",
            "  C. Represents a user interface.\n",
            "  D. Holds only numerical values.\n",
            "\n",
            "Correct Answer: Stores certain information that can change based on conditions.\n",
            "\n",
            "Question 5:\n",
            "Question: What type of agent is discussed in the video?\n",
            "Options:\n",
            "  A. Data agent.\n",
            "  B. React agent.\n",
            "  C. Web agent.\n",
            "  D. Mobile agent.\n",
            "\n",
            "Correct Answer: React agent.\n",
            "\n",
            "Question 6:\n",
            "Question: What is the first step to coding with LangGraph?\n",
            "Options:\n",
            "  A. Create a user interface.\n",
            "  B. Install all the necessary dependencies.\n",
            "  C. Design a database schema.\n",
            "  D. Write documentation.\n",
            "\n",
            "Correct Answer: Install all the necessary dependencies.\n",
            "\n",
            "Question 7:\n",
            "Question: What tools are used in the simple example provided?\n",
            "Options:\n",
            "  A. Search tool and calculator tool.\n",
            "  B. Database tool and rendering tool.\n",
            "  C. Authentication tool and logging tool.\n",
            "  D. UI tool and API tool.\n",
            "\n",
            "Correct Answer: Search tool and calculator tool.\n",
            "\n",
            "Question 8:\n",
            "Question: What does the 'Multiply' function do in the context of LangGraph?\n",
            "Options:\n",
            "  A. It adds two integers.\n",
            "  B. It takes two integers and returns their multiplied answer.\n",
            "  C. It divides two integers.\n",
            "  D. It finds the maximum of two integers.\n",
            "\n",
            "Correct Answer: It takes two integers and returns their multiplied answer.\n",
            "\n",
            "Question 9:\n",
            "Question: How can you visualize the graph in LangGraph?\n",
            "Options:\n",
            "  A. By using a separate visualization tool.\n",
            "  B. By running the LangGraph code.\n",
            "  C. By exporting it to PDF.\n",
            "  D. By drawing it manually.\n",
            "\n",
            "Correct Answer: By running the LangGraph code.\n",
            "\n",
            "Question 10:\n",
            "Question: What type of reasoning does the agent in LangGraph perform?\n",
            "Options:\n",
            "  A. Single-step reasoning.\n",
            "  B. Multi-step reasoning.\n",
            "  C. Randomized reasoning.\n",
            "  D. No reasoning.\n",
            "\n",
            "Correct Answer: Multi-step reasoning.\n",
            "\n",
            "Question 11:\n",
            "Question: What is the output of the agent when asked to calculate '5 times the current age of Shahrukh Khan'?\n",
            "Options:\n",
            "  A. It guesses the answer.\n",
            "  B. It performs a search to find the age and then multiplies it.\n",
            "  C. It uses predefined values.\n",
            "  D. It cannot answer this question.\n",
            "\n",
            "Correct Answer: It performs a search to find the age and then multiplies it.\n",
            "\n",
            "Question 12:\n",
            "Question: In the more complicated example, how many tools are used?\n",
            "Options:\n",
            "  A. One tool.\n",
            "  B. Two tools.\n",
            "  C. Three tools.\n",
            "  D. Four tools.\n",
            "\n",
            "Correct Answer: Three tools.\n",
            "\n",
            "Question 13:\n",
            "Question: What is the purpose of the square root tool in the complicated example?\n",
            "Options:\n",
            "  A. To multiply numbers.\n",
            "  B. To calculate the square root as part of the multi-step reasoning.\n",
            "  C. To divide numbers.\n",
            "  D. To sum numbers.\n",
            "\n",
            "Correct Answer: To calculate the square root as part of the multi-step reasoning.\n",
            "\n",
            "Question 14:\n",
            "Question: What is the question posed in the complicated example?\n",
            "Options:\n",
            "  A. What is the square root of 4 raised to the power of 10 multiplied by 5?\n",
            "  B. What is 10 times 5?\n",
            "  C. What is the square of 4?\n",
            "  D. What is the power of 5?\n",
            "\n",
            "Correct Answer: What is the square root of 4 raised to the power of 10 multiplied by 5?\n",
            "\n",
            "Question 15:\n",
            "Question: What framework is LangGraph a part of?\n",
            "Options:\n",
            "  A. TensorFlow ecosystem.\n",
            "  B. LangChain ecosystem.\n",
            "  C. SciKit Learn ecosystem.\n",
            "  D. Pandas ecosystem.\n",
            "\n",
            "Correct Answer: LangChain ecosystem.\n",
            "\n",
            "Question 16:\n",
            "Question: How does LangGraph handle agent loops?\n",
            "Options:\n",
            "  A. Agents cannot loop.\n",
            "  B. Agents can loop back to a node until the problem is solved.\n",
            "  C. Agents only operate linearly.\n",
            "  D. Agents skip nodes.\n",
            "\n",
            "Correct Answer: Agents can loop back to a node until the problem is solved.\n",
            "\n",
            "Question 17:\n",
            "Question: What is a decorator in the context of defining tools in LangGraph?\n",
            "Options:\n",
            "  A. A method to optimize performance.\n",
            "  B. A special syntax that converts a function into a tool.\n",
            "  C. A way to document code.\n",
            "  D. A tool for error handling.\n",
            "\n",
            "Correct Answer: A special syntax that converts a function into a tool.\n",
            "\n",
            "Question 18:\n",
            "Question: What is the goal of the next video mentioned in the transcript?\n",
            "Options:\n",
            "  A. To learn about data visualization.\n",
            "  B. To learn more about different agent frameworks.\n",
            "  C. To debug code.\n",
            "  D. To install software.\n",
            "\n",
            "Correct Answer: To learn more about different agent frameworks.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from educhain import Educhain\n",
        "\n",
        "client = Educhain()\n",
        "\n",
        "ques = client.qna_engine.generate_questions_from_data(source = text_2, num = 20, custom_instructions=\"Refer the transcript as things taught and create MCQ's on the same dont ask questions about the docuemnt. Make sure the questions are such that they cover all topics and also after the quiz the student will have a clear understanding of the topic\", source_type=\"text\")"
      ],
      "metadata": {
        "id": "3VrPj8zZkR8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ques.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbtj4V4-kZS7",
        "outputId": "6300e4ae-6aca-4167-c0bc-26ce8aebc173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1:\n",
            "Question: What is pandas AI?\n",
            "Options:\n",
            "  A. A Python library that integrates AI capabilities with pandas data frames.\n",
            "  B. A database management system.\n",
            "  C. A visualization tool for Python.\n",
            "  D. A machine learning framework.\n",
            "\n",
            "Correct Answer: A Python library that integrates AI capabilities with pandas data frames.\n",
            "Explanation: Pandas AI enhances the traditional pandas library by allowing users to perform data analysis using natural language queries.\n",
            "\n",
            "Question 2:\n",
            "Question: What does pandas primarily allow users to do?\n",
            "Options:\n",
            "  A. Create website front-ends.\n",
            "  B. Analyze data sets.\n",
            "  C. Manage databases.\n",
            "  D. Design user interfaces.\n",
            "\n",
            "Correct Answer: Analyze data sets.\n",
            "Explanation: Pandas is a widely used library in Python that helps with data manipulation and analysis.\n",
            "\n",
            "Question 3:\n",
            "Question: How does pandas AI facilitate data analysis?\n",
            "Options:\n",
            "  A. Through graphical user interfaces.\n",
            "  B. By requiring complex SQL queries.\n",
            "  C. Through natural language queries.\n",
            "  D. By using command-line tools.\n",
            "\n",
            "Correct Answer: Through natural language queries.\n",
            "Explanation: Pandas AI allows users to interact with data using simple conversational queries instead of complex code.\n",
            "\n",
            "Question 4:\n",
            "Question: What type of data manipulation does pandas AI support?\n",
            "Options:\n",
            "  A. Only manual data manipulation.\n",
            "  B. Smart data cleaning and automated statistical analysis.\n",
            "  C. Only data visualization.\n",
            "  D. Only database connections.\n",
            "\n",
            "Correct Answer: Smart data cleaning and automated statistical analysis.\n",
            "Explanation: Pandas AI enhances traditional pandas operations by adding features like smart data cleaning and automated analysis.\n",
            "\n",
            "Question 5:\n",
            "Question: What is required to create a smart data frame in pandas AI?\n",
            "Options:\n",
            "  A. Just a data frame.\n",
            "  B. A data frame and an LLM (Large Language Model).\n",
            "  C. Only a CSV file.\n",
            "  D. A data frame and a SQL query.\n",
            "\n",
            "Correct Answer: A data frame and an LLM (Large Language Model).\n",
            "Explanation: To create a smart data frame, you must provide both a data frame and specify which LLM to use.\n",
            "\n",
            "Question 6:\n",
            "Question: What can you ask pandas AI to visualize?\n",
            "Options:\n",
            "  A. Only numerical data.\n",
            "  B. Charts and graphs based on data queries.\n",
            "  C. Only summary statistics.\n",
            "  D. No visualizations are supported.\n",
            "\n",
            "Correct Answer: Charts and graphs based on data queries.\n",
            "Explanation: Users can request visualizations such as bar charts or pie charts directly through natural language prompts.\n",
            "\n",
            "Question 7:\n",
            "Question: Which AI model is mentioned as being used with pandas AI?\n",
            "Options:\n",
            "  A. Google AI.\n",
            "  B. OpenAI models.\n",
            "  C. IBM Watson.\n",
            "  D. Microsoft Azure AI.\n",
            "\n",
            "Correct Answer: OpenAI models.\n",
            "Explanation: In the video, the speaker mentions using OpenAI models for data analysis with pandas AI.\n",
            "\n",
            "Question 8:\n",
            "Question: What type of queries can users perform in pandas AI?\n",
            "Options:\n",
            "  A. Only complex SQL queries.\n",
            "  B. Simple natural language queries.\n",
            "  C. Only queries in Python code.\n",
            "  D. Only queries in JSON format.\n",
            "\n",
            "Correct Answer: Simple natural language queries.\n",
            "Explanation: Pandas AI allows users to perform queries in natural language, making it more accessible for data analysis.\n",
            "\n",
            "Question 9:\n",
            "Question: What is a notable feature of pandas AI regarding data visualization?\n",
            "Options:\n",
            "  A. It requires manual code for visualization.\n",
            "  B. It can automatically create visualizations based on queries.\n",
            "  C. It does not support visualizations.\n",
            "  D. It only provides static images.\n",
            "\n",
            "Correct Answer: It can automatically create visualizations based on queries.\n",
            "Explanation: Pandas AI's ability to generate visualizations from queries enhances the data analysis process by providing immediate graphical insights.\n",
            "\n",
            "Question 10:\n",
            "Question: How does pandas AI handle multi-query prompts?\n",
            "Options:\n",
            "  A. It cannot handle multiple queries.\n",
            "  B. It can process multiple queries at once and provide a comprehensive analysis.\n",
            "  C. It only answers the first query.\n",
            "  D. It requires separate requests for each query.\n",
            "\n",
            "Correct Answer: It can process multiple queries at once and provide a comprehensive analysis.\n",
            "Explanation: The capability to handle multi-query prompts allows for more complex data analysis in a single request.\n",
            "\n",
            "Question 11:\n",
            "Question: What was the Titanic data set used to demonstrate?\n",
            "Options:\n",
            "  A. Stock market analysis.\n",
            "  B. Customer feedback analysis.\n",
            "  C. Various queries and visualizations related to passenger data.\n",
            "  D. Weather data prediction.\n",
            "\n",
            "Correct Answer: Various queries and visualizations related to passenger data.\n",
            "Explanation: The Titanic data set was used to illustrate how pandas AI can answer questions and generate visualizations based on that data.\n",
            "\n",
            "Question 12:\n",
            "Question: What kind of analysis can be performed with pandas AI on age distribution?\n",
            "Options:\n",
            "  A. Only average age.\n",
            "  B. Average, minimum, and maximum ages of passengers.\n",
            "  C. Only maximum age.\n",
            "  D. No age-related analysis is possible.\n",
            "\n",
            "Correct Answer: Average, minimum, and maximum ages of passengers.\n",
            "Explanation: Users can request specific statistics such as average, minimum, and maximum ages to analyze the age distribution of passengers.\n",
            "\n",
            "Question 13:\n",
            "Question: What kind of graphs can be generated with pandas AI?\n",
            "Options:\n",
            "  A. Only line graphs.\n",
            "  B. Bar charts, pie charts, and other types of visualizations.\n",
            "  C. Only scatter plots.\n",
            "  D. No graphs can be generated.\n",
            "\n",
            "Correct Answer: Bar charts, pie charts, and other types of visualizations.\n",
            "Explanation: Users can ask for different types of visualizations like bar charts or pie charts based on their queries.\n",
            "\n",
            "Question 14:\n",
            "Question: What is the benefit of using pandas AI for data analysis?\n",
            "Options:\n",
            "  A. It complicates the data analysis process.\n",
            "  B. It requires advanced programming skills.\n",
            "  C. It simplifies the process of analyzing data by allowing natural language interactions.\n",
            "  D. It is only for data scientists.\n",
            "\n",
            "Correct Answer: It simplifies the process of analyzing data by allowing natural language interactions.\n",
            "Explanation: Pandas AI makes data analysis more accessible to users who may not be familiar with programming or complex queries.\n",
            "\n",
            "Question 15:\n",
            "Question: What happens if an error occurs while using pandas AI?\n",
            "Options:\n",
            "  A. The program crashes.\n",
            "  B. You can run the model again to potentially get better answers.\n",
            "  C. You must restart your computer.\n",
            "  D. No action can be taken.\n",
            "\n",
            "Correct Answer: You can run the model again to potentially get better answers.\n",
            "Explanation: If errors occur during analysis, users can re-run the queries to try and obtain correct results.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding custom instructions to ensure generic questions â­"
      ],
      "metadata": {
        "id": "PRolClv_nC6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"0:01 Hi, everyone. Welcome to this module. In this module, we will talk everything about Genitive A, chatbots. Let me explain the significance of chatbots through few slides and then I will try to cover what are the things that you will learn in this particular module.\n",
        "0:19 Chatbots, chatbots, chatbots, chatbots. So everywhere you see whenever you interact with Genitive A, mostly it is through a chatbot. So if you look at how most of the world has interacted with generative way, it is through a chatbot.\n",
        "0:32 So most of the people have interacted with chat GPT, which is primarily a chat application. So if you want to interact with generative way as of today, a majority of people do that using a chatbot.\n",
        "0:44 So most of the generative way applications also have a chat interface. So I'll give you a few examples short. Having said that, if 80% or 90% of generative applications that are coming out today are based on a chat interface, it is very important for you to understand inner workings of the chatbot.\n",
        "1:05 Not just to be able to build the applications, but also to understand with the systems that you are interacting with.\n",
        "1:13 So it is very essential that you understand the concept of chatbots, how they are built, how you can build some of them and how do they internally work.\n",
        "1:21 So there are many many use cases of chatbots starting from a simple use case like a chatbot on your website where a user can come and talk to the website.\n",
        "1:31 So that is a form of chatbot. So there are a lot of Chrome extensions these days where you can just download a plugin and chat with the YouTube video that you're watching.\n",
        "1:40 So, there are chatbots like perplexity that we have introduced before, they also form a chat interface. So, this is not a simple chat interface, they all come with additional features like perplexity is a chatbot with internet functionality.\n",
        "1:57 So, let's say this particular chatbot is a chat interface with knowledge to a particular website's data. So, so is this particular plugin which has knowledge of that particular YouTube video.\n",
        "2:09 So, what we will try to do is that, in this module, the first part of what we will cover is to understand how these conversion chatbots work and in the next part of the module, we will try to understand concepts like RAG where you can ingest your own data like PDF, website URLs and videos to create these\n",
        "2:27 applications. To be able to do all of these things, you need to understand some core concepts of how to build these chatbots.\n",
        "2:35 So, few of the topics include chat completion API, so we have been working with the chat completion API even though you don't know, so I'll explain more about that.\n",
        "2:46 So, there are a lot of types of chat, different types of chat messages that you need to understand. And there is an important concept of memory, so whenever you are developing a chat board, memory is going to be a very important concept.\n",
        "3:00 So, after learning all these three concepts, I will show you some chat templates, which will allow you to create and deploy chatbots very easily.\n",
        "3:09 So, in the next lecture, I will cover these two topics, we will meet you there.\"\"\""
      ],
      "metadata": {
        "id": "9cunLYmGkikg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Instructions"
      ],
      "metadata": {
        "id": "f6eBt0gwOwvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from educhain import Educhain\n",
        "\n",
        "client = Educhain()\n",
        "\n",
        "instructions = \"\"\"Focus on Key Concepts:\n",
        "Extract the main ideas and technical concepts discussed in the transcript\n",
        "Avoid Context-Specific References:\n",
        "Do not include questions tied to the video or module itself\n",
        ". Instead, create questions that are conceptually relevant and independent of the video context.\n",
        "Encourage Application and Understanding:\n",
        "Frame questions to encourage understanding of concepts and their applications\n",
        "Diverse Question Types:\n",
        "Include a variety of question types, such as:\n",
        "Conceptual: What are the key components of a chatbot?\n",
        "Analytical: How does memory improve user experience in chatbots?\n",
        "Comparative: How are chatbots with internet functionality different from regular chatbots?\n",
        "Avoid Repetition:\n",
        "Ensure each question is unique and covers different aspects of the transcript.\n",
        "\n",
        "Generalize Use Cases:\n",
        "When referencing use cases, frame them in a broader context\n",
        "\n",
        "Maintain Clarity:\n",
        "Keep questions clear, concise, and relevant to the transcript's concepts.\n",
        "\n",
        "Focus on Learning Objectives:\n",
        "Ensure questions align with learning objectives such as understanding chatbots, their components, their features, and their use in generative AI applications.\"\"\"\n",
        "\n",
        "ques = client.qna_engine.generate_questions_from_data(source = text, num = 10, custom_instructions=instructions, source_type=\"text\")"
      ],
      "metadata": {
        "id": "PU49RKRYnJBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ques.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhXwbs7pnMUR",
        "outputId": "f7abcd52-2c64-434c-9e3b-09631ccc1c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1:\n",
            "Question: What is a primary interface through which most people interact with generative AI?\n",
            "Options:\n",
            "  A. Voice Assistant\n",
            "  B. Chatbot\n",
            "  C. Email\n",
            "  D. Video Call\n",
            "\n",
            "Correct Answer: Chatbot\n",
            "Explanation: Chatbots are the most common interface for users to interact with generative AI applications, such as ChatGPT.\n",
            "\n",
            "Question 2:\n",
            "Question: Which component is essential for understanding how chatbots retain information during conversations?\n",
            "Options:\n",
            "  A. User Interface\n",
            "  B. Database\n",
            "  C. Memory\n",
            "  D. Algorithm\n",
            "\n",
            "Correct Answer: Memory\n",
            "Explanation: Memory is a critical component in chatbots that allows them to retain context and improve user experience over successive interactions.\n",
            "\n",
            "Question 3:\n",
            "Question: What type of chatbot provides additional functionality by accessing the internet?\n",
            "Options:\n",
            "  A. Basic Chatbot\n",
            "  B. Chatbot with internet functionality\n",
            "  C. Static Chatbot\n",
            "  D. Local Chatbot\n",
            "\n",
            "Correct Answer: Chatbot with internet functionality\n",
            "Explanation: Chatbots with internet functionality can pull real-time data from the web, enhancing their responses and capabilities.\n",
            "\n",
            "Question 4:\n",
            "Question: What is one common use case for chatbots on websites?\n",
            "Options:\n",
            "  A. E-commerce transactions\n",
            "  B. Social media marketing\n",
            "  C. Customer support\n",
            "  D. Content creation\n",
            "\n",
            "Correct Answer: Customer support\n",
            "Explanation: Chatbots are often used on websites to provide customer support, answering queries and assisting users in real time.\n",
            "\n",
            "Question 5:\n",
            "Question: Which API is commonly used in developing chatbots?\n",
            "Options:\n",
            "  A. Data Retrieval API\n",
            "  B. Chat completion API\n",
            "  C. Authentication API\n",
            "  D. Payment Processing API\n",
            "\n",
            "Correct Answer: Chat completion API\n",
            "Explanation: The Chat Completion API is crucial for building chatbots, facilitating the generation of responses based on user input.\n",
            "\n",
            "Question 6:\n",
            "Question: What do chatbots need to do to create applications that can ingest their own data?\n",
            "Options:\n",
            "  A. Only process text\n",
            "  B. Understand concepts like RAG\n",
            "  C. Connect to databases directly\n",
            "  D. Limit interactions to pre-defined scripts\n",
            "\n",
            "Correct Answer: Understand concepts like RAG\n",
            "Explanation: Understanding concepts like RAG (Retrieval-Augmented Generation) is necessary for chatbots to incorporate and utilize external data sources effectively.\n",
            "\n",
            "Question 7:\n",
            "Question: What is one feature that can enhance a chatbot's interaction with users?\n",
            "Options:\n",
            "  A. Static responses\n",
            "  B. Contextual understanding\n",
            "  C. Limited vocabulary\n",
            "  D. Pre-set answers\n",
            "\n",
            "Correct Answer: Contextual understanding\n",
            "Explanation: Contextual understanding allows chatbots to provide more relevant and tailored responses based on previous interactions.\n",
            "\n",
            "Question 8:\n",
            "Question: In the context of chatbots, what does RAG stand for?\n",
            "Options:\n",
            "  A. Responsive AI Generation\n",
            "  B. Rapid Algorithm Generation\n",
            "  C. Retrieval-Augmented Generation\n",
            "  D. Randomized Answer Generator\n",
            "\n",
            "Correct Answer: Retrieval-Augmented Generation\n",
            "Explanation: RAG refers to a method that combines retrieval of external data with generative capabilities to enhance responses.\n",
            "\n",
            "Question 9:\n",
            "Question: What is an example of a chatbot plugin mentioned in the discussion?\n",
            "Options:\n",
            "  A. Slackbot\n",
            "  B. Perplexity\n",
            "  C. Discord Bot\n",
            "  D. Twitch Chatbot\n",
            "\n",
            "Correct Answer: Perplexity\n",
            "Explanation: Perplexity is a chatbot with internet functionality that can provide information based on external sources.\n",
            "\n",
            "Question 10:\n",
            "Question: Why is it important to understand the inner workings of chatbots?\n",
            "Options:\n",
            "  A. To sell them\n",
            "  B. To effectively build and interact with them\n",
            "  C. To limit their usage\n",
            "  D. To troubleshoot only\n",
            "\n",
            "Correct Answer: To effectively build and interact with them\n",
            "Explanation: Understanding how chatbots operate enables developers to create better applications and users to utilize them more effectively.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}