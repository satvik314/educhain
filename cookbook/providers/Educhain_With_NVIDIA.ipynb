{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Shubhwithai/GRE_Geometry_quiz/blob/main/Group%2042.png?raw=true\" width=\"\" height=\"50\">\n",
        "\n",
        "Educhain is a powerful Python package that leverages Generative AI to create\n",
        "engaging and personalized educational content. From generating multiple-choice questions to crafting comprehensive lesson plans, Educhain makes it easy to apply AI in various educational scenarios."
      ],
      "metadata": {
        "id": "Mz8bgljA2xo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1G9l9b-Q-ObG6JY-XHKzYDpmYW6TOrPNU?usp=sharing)"
      ],
      "metadata": {
        "id": "thiLtYCOPUC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/satvik314/educhain/blob/main/images/educhain_diagram.png?raw=true\" width=\"800\" height=\"500\">\n"
      ],
      "metadata": {
        "id": "r1rJRhc6J_W2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to Use Educhain With NVIDIA Model\n",
        "---"
      ],
      "metadata": {
        "id": "tIQKcRCVbBzT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setup"
      ],
      "metadata": {
        "id": "Bgdt6TlVI3v5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7inIre43Ua6D",
        "outputId": "df6e80ed-a054-4756-d2fd-bf0c5fd41647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\n",
            "Collecting langchain-nvidia-ai-endpoints\n",
            "  Downloading langchain_nvidia_ai_endpoints-0.3.9-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting educhain\n",
            "  Downloading educhain-0.3.8-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.50)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.23)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from langchain-nvidia-ai-endpoints) (3.11.15)\n",
            "Collecting langchain-community (from educhain)\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-openai (from educhain)\n",
            "  Downloading langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from educhain) (1.70.0)\n",
            "Collecting python-dotenv (from educhain)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting reportlab (from educhain)\n",
            "  Downloading reportlab-4.3.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting PyPDF2 (from educhain)\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from educhain) (4.13.3)\n",
            "Collecting youtube-transcript-api (from educhain)\n",
            "  Downloading youtube_transcript_api-1.0.3-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting chromadb (from educhain)\n",
            "  Downloading chromadb-1.0.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting protobuf<5 (from educhain)\n",
            "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from educhain) (11.1.0)\n",
            "Collecting dataframe-image (from educhain)\n",
            "  Downloading dataframe_image-0.2.7-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting langchain-google-genai (from educhain)\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from educhain) (2.2.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from educhain) (7.34.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from educhain) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from educhain) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.18.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (4.13.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->educhain) (2.6)\n",
            "Collecting build>=1.0.3 (from chromadb->educhain)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb->educhain)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi==0.115.9 (from chromadb->educhain)\n",
            "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb->educhain)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb->educhain)\n",
            "  Downloading posthog-3.23.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb->educhain)\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb->educhain) (1.31.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb->educhain) (1.31.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb->educhain) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb->educhain)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb->educhain) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb->educhain)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb->educhain) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb->educhain) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb->educhain)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb->educhain) (0.15.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb->educhain)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb->educhain)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb->educhain) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb->educhain) (4.23.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb->educhain)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from dataframe-image->educhain) (7.16.6)\n",
            "Requirement already satisfied: mistune in /usr/local/lib/python3.11/dist-packages (from dataframe-image->educhain) (3.1.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from dataframe-image->educhain) (5.3.1)\n",
            "Collecting cssutils (from dataframe-image->educhain)\n",
            "  Downloading cssutils-2.11.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting playwright (from dataframe-image->educhain)\n",
            "  Downloading playwright-1.51.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting cssselect (from dataframe-image->educhain)\n",
            "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->educhain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->educhain) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->educhain) (2025.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->educhain) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython->educhain)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->educhain) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->educhain) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->educhain) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->educhain) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->educhain) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->educhain) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->educhain) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->educhain) (4.9.0)\n",
            "Collecting langchain-core<1.0.0,>=0.3.49 (from langchain)\n",
            "  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community->educhain)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community->educhain)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community->educhain)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai->educhain)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai->educhain)\n",
            "  Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai->educhain)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai->educhain) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai->educhain) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai->educhain) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai->educhain) (1.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->educhain) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->educhain) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->educhain) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->educhain) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->educhain) (3.2.3)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from reportlab->educhain) (5.2.0)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api->educhain) (0.7.1)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb->educhain)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->educhain)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->educhain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai->educhain) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai->educhain) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai->educhain) (1.26.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->educhain) (0.8.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb->educhain) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb->educhain) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb->educhain) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb->educhain) (1.17.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb->educhain) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb->educhain) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb->educhain) (3.2.2)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb->educhain)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->dataframe-image->educhain) (6.2.0)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->dataframe-image->educhain) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->dataframe-image->educhain) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->dataframe-image->educhain) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->dataframe-image->educhain) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->dataframe-image->educhain) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->dataframe-image->educhain) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->dataframe-image->educhain) (1.5.1)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb->educhain)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb->educhain) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb->educhain) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb->educhain) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb->educhain) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain) (1.69.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_proto-1.31.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_proto-1.31.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_proto-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_proto-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->educhain)\n",
            "  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation-0.52b1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain) (0.52b1)\n",
            "Collecting opentelemetry-util-http==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_util_http-0.52b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-semantic-conventions==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation-0.52b0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_semantic_conventions-0.52b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_util_http-0.52b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_api-1.31.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb->educhain)\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_api-1.29.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_api-1.28.2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.49b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.49b1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_util_http-0.49b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_api-1.28.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.49b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.49b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_semantic_conventions-0.49b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_util_http-0.49b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_api-1.28.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "INFO: pip is still looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->educhain)\n",
            "  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb->educhain)\n",
            "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting importlib-metadata<=8.4.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb->educhain)\n",
            "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->educhain) (0.7.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb->educhain)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb->educhain)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->educhain) (0.2.13)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb->educhain) (3.0.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai->educhain) (2024.11.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb->educhain) (0.30.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb->educhain) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb->educhain) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb->educhain)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb->educhain)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb->educhain)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->educhain) (15.0.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from cssutils->dataframe-image->educhain) (10.6.0)\n",
            "Collecting pyee<13,>=12 (from playwright->dataframe-image->educhain)\n",
            "  Downloading pyee-12.1.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->dataframe-image->educhain) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->dataframe-image->educhain) (1.4.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai->educhain) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai->educhain) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai->educhain) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai->educhain) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb->educhain) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb->educhain) (2025.3.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->educhain) (3.21.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.7->nbconvert>=5->dataframe-image->educhain) (4.3.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->educhain) (0.1.2)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from nbclient>=0.5.0->nbconvert>=5->dataframe-image->educhain) (6.1.12)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert>=5->dataframe-image->educhain) (2.21.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->educhain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb->educhain)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb->educhain) (1.3.0)\n",
            "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai->educhain)\n",
            "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=5->dataframe-image->educhain) (24.0.1)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=5->dataframe-image->educhain) (6.4.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai->educhain) (0.6.1)\n",
            "Downloading langchain_nvidia_ai_endpoints-0.3.9-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading educhain-0.3.8-py3-none-any.whl (28 kB)\n",
            "Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.0.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataframe_image-0.2.7-py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.51-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Downloading langchain_google_genai-2.1.2-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.12-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading reportlab-4.3.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading youtube_transcript_api-1.0.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m429.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
            "Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.23.0-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
            "Downloading cssutils-2.11.1-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.7/385.7 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading playwright-1.51.0-py3-none-manylinux1_x86_64.whl (45.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading pyee-12.1.1-py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading grpcio_status-1.62.3-py3-none-any.whl (14 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53800 sha256=a48bd34ebacb632c1e6b39402d35e849866a0fd979d8a5807e6af3728f6f64d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, filetype, durationpy, uvloop, uvicorn, reportlab, python-dotenv, pyproject_hooks, PyPDF2, pyee, protobuf, overrides, opentelemetry-util-http, mypy-extensions, mmh3, marshmallow, jedi, importlib-metadata, humanfriendly, httpx-sse, httptools, cssutils, cssselect, chroma-hnswlib, bcrypt, backoff, asgiref, youtube-transcript-api, watchfiles, typing-inspect, tiktoken, starlette, posthog, playwright, opentelemetry-proto, opentelemetry-api, coloredlogs, build, pydantic-settings, opentelemetry-semantic-conventions, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, grpcio-status, fastapi, dataclasses-json, opentelemetry-sdk, opentelemetry-instrumentation-asgi, langchain-core, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain-openai, langchain-nvidia-ai-endpoints, google-ai-generativelanguage, langchain-google-genai, langchain, chromadb, langchain-community, dataframe-image, educhain\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.31.1\n",
            "    Uninstalling opentelemetry-api-1.31.1:\n",
            "      Successfully uninstalled opentelemetry-api-1.31.1\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.52b1\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.52b1:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.52b1\n",
            "  Attempting uninstall: grpcio-status\n",
            "    Found existing installation: grpcio-status 1.71.0\n",
            "    Uninstalling grpcio-status-1.71.0:\n",
            "      Successfully uninstalled grpcio-status-1.71.0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.31.1\n",
            "    Uninstalling opentelemetry-sdk-1.31.1:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.31.1\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.50\n",
            "    Uninstalling langchain-core-0.3.50:\n",
            "      Successfully uninstalled langchain-core-0.3.50\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.7\n",
            "    Uninstalling langchain-text-splitters-0.3.7:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.7\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.22\n",
            "    Uninstalling langchain-0.3.22:\n",
            "      Successfully uninstalled langchain-0.3.22\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyPDF2-3.0.1 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-1.0.0 coloredlogs-15.0.1 cssselect-1.3.0 cssutils-2.11.1 dataclasses-json-0.6.7 dataframe-image-0.2.7 durationpy-0.9 educhain-0.3.8 fastapi-0.115.9 filetype-1.2.0 google-ai-generativelanguage-0.6.17 grpcio-status-1.62.3 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 importlib-metadata-8.4.0 jedi-0.19.2 kubernetes-32.0.1 langchain-0.3.23 langchain-community-0.3.21 langchain-core-0.3.51 langchain-google-genai-2.1.2 langchain-nvidia-ai-endpoints-0.3.9 langchain-openai-0.3.12 langchain-text-splitters-0.3.8 marshmallow-3.26.1 mmh3-5.1.0 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.21.0 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 overrides-7.7.0 playwright-1.51.0 posthog-3.23.0 protobuf-4.25.6 pydantic-settings-2.8.1 pyee-12.1.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.0 reportlab-4.3.1 starlette-0.45.3 tiktoken-0.9.0 typing-inspect-0.9.0 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4 youtube-transcript-api-1.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "importlib_metadata"
                ]
              },
              "id": "b7d482240ccf4867bc1106e72743694e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install langchain langchain-nvidia-ai-endpoints educhain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Imports"
      ],
      "metadata": {
        "id": "Xy8GMfeJJV3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "from google.colab import userdata\n",
        "from educhain import Educhain, LLMConfig"
      ],
      "metadata": {
        "id": "AvyyAE5sUgzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setup API Keys"
      ],
      "metadata": {
        "id": "ImU0ooSAJYwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your Nvidia AI API key\n",
        "os.environ[\"NVIDIA_API_KEY\"] = userdata.get(\"NVIDIA_API_KEY\")"
      ],
      "metadata": {
        "id": "5_fT4ynFUjyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Quickstart**\n",
        "\n"
      ],
      "metadata": {
        "id": "JL6Uq5tFYstX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Configure Nvidia-AI Model"
      ],
      "metadata": {
        "id": "W5vJF1He71Nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Nvidia = ChatNVIDIA(\n",
        "    model=\"meta/llama-4-maverick-17b-128e-instruct\",\n",
        ")\n",
        "Nvidia_config = LLMConfig(custom_model=Nvidia)"
      ],
      "metadata": {
        "id": "3fvWl2-076vu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c6c4a31-3e27-4122-b417-517c8081e148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_nvidia_ai_endpoints/_common.py:212: UserWarning: Found meta/llama-4-maverick-17b-128e-instruct in available_models, but type is unknown and inference may fail.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Create MCQs just by entering the topic**"
      ],
      "metadata": {
        "id": "lwmxYuPO8G1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = Educhain(Nvidia_config)\n",
        "\n",
        "ques = client.qna_engine.generate_questions(topic=\"Agentic Ai\",\n",
        "                                            num=5,\n",
        "                                            level=\"Easy\")\n",
        "ques.model_dump_json()   #you can Generate Dictionaries with this model_dump_json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "94pzqvrs7VaX",
        "outputId": "f9a24a83-1ed8-4775-a225-54305be44856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"questions\":[{\"question\":\"What is the primary characteristic of Agentic AI?\",\"answer\":\"Autonomy\",\"explanation\":\"Agentic AI is designed to operate independently, making decisions and taking actions without human intervention.\",\"options\":[\"Autonomy\",\"Supervision\",\"Collaboration\",\"Automation\"]},{\"question\":\"Which of the following is a potential application of Agentic AI?\",\"answer\":\"Smart Homes\",\"explanation\":\"Agentic AI can be used to control and manage various aspects of a smart home, such as temperature, lighting, and security.\",\"options\":[\"Smart Homes\",\"Image Recognition\",\"Natural Language Processing\",\"Predictive Maintenance\"]},{\"question\":\"What is a key challenge in developing Agentic AI?\",\"answer\":\"Ensuring Safety and Security\",\"explanation\":\"As Agentic AI operates autonomously, ensuring its safety and security is crucial to prevent potential harm or damage.\",\"options\":[\"Ensuring Safety and Security\",\"Improving Accuracy\",\"Reducing Complexity\",\"Increasing Efficiency\"]},{\"question\":\"How does Agentic AI differ from traditional AI?\",\"answer\":\"It can make decisions autonomously\",\"explanation\":\"Agentic AI has the ability to make decisions and take actions without human intervention, whereas traditional AI typically relies on human input and guidance.\",\"options\":[\"It can process large amounts of data\",\"It can make decisions autonomously\",\"It is more accurate than traditional AI\",\"It is less complex than traditional AI\"]},{\"question\":\"What is a potential benefit of Agentic AI?\",\"answer\":\"Increased Productivity\",\"explanation\":\"Agentic AI can automate various tasks and processes, leading to increased productivity and efficiency.\",\"options\":[\"Increased Productivity\",\"Improved Accuracy\",\"Enhanced Customer Experience\",\"Reduced Costs\"]}]}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ques.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOA-wz7o8kiu",
        "outputId": "b8964776-675c-45c7-e918-943b4c4327c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1:\n",
            "Question: What is the primary characteristic of Agentic AI?\n",
            "Options:\n",
            "  A. Autonomy\n",
            "  B. Supervision\n",
            "  C. Collaboration\n",
            "  D. Automation\n",
            "\n",
            "Correct Answer: Autonomy\n",
            "Explanation: Agentic AI is designed to operate independently, making decisions and taking actions without human intervention.\n",
            "\n",
            "Question 2:\n",
            "Question: Which of the following is a potential application of Agentic AI?\n",
            "Options:\n",
            "  A. Smart Homes\n",
            "  B. Image Recognition\n",
            "  C. Natural Language Processing\n",
            "  D. Predictive Maintenance\n",
            "\n",
            "Correct Answer: Smart Homes\n",
            "Explanation: Agentic AI can be used to control and manage various aspects of a smart home, such as temperature, lighting, and security.\n",
            "\n",
            "Question 3:\n",
            "Question: What is a key challenge in developing Agentic AI?\n",
            "Options:\n",
            "  A. Ensuring Safety and Security\n",
            "  B. Improving Accuracy\n",
            "  C. Reducing Complexity\n",
            "  D. Increasing Efficiency\n",
            "\n",
            "Correct Answer: Ensuring Safety and Security\n",
            "Explanation: As Agentic AI operates autonomously, ensuring its safety and security is crucial to prevent potential harm or damage.\n",
            "\n",
            "Question 4:\n",
            "Question: How does Agentic AI differ from traditional AI?\n",
            "Options:\n",
            "  A. It can process large amounts of data\n",
            "  B. It can make decisions autonomously\n",
            "  C. It is more accurate than traditional AI\n",
            "  D. It is less complex than traditional AI\n",
            "\n",
            "Correct Answer: It can make decisions autonomously\n",
            "Explanation: Agentic AI has the ability to make decisions and take actions without human intervention, whereas traditional AI typically relies on human input and guidance.\n",
            "\n",
            "Question 5:\n",
            "Question: What is a potential benefit of Agentic AI?\n",
            "Options:\n",
            "  A. Increased Productivity\n",
            "  B. Improved Accuracy\n",
            "  C. Enhanced Customer Experience\n",
            "  D. Reduced Costs\n",
            "\n",
            "Correct Answer: Increased Productivity\n",
            "Explanation: Agentic AI can automate various tasks and processes, leading to increased productivity and efficiency.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###You can also pass level, number of questions and custom instructions as an input"
      ],
      "metadata": {
        "id": "E6sTBX5s89SF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = Educhain(Nvidia_config)\n",
        "\n",
        "ques = client.qna_engine.generate_questions(topic=\"Agentic Ai\",\n",
        "                                            num=5,\n",
        "                                            level= \"Medium\",\n",
        "                                            custom_instructions=\"Focus on Latest Trends Of Agentic AI Frameworks\")\n",
        "ques.model_dump()  #you can Generate Dictionaries with this model_dump()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIeP94H88_AA",
        "outputId": "54ebb4ab-a62c-46e0-961d-7b198f66f494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'questions': [{'question': 'What is the primary characteristic of Agentic AI frameworks?',\n",
              "   'answer': 'Autonomy',\n",
              "   'explanation': 'Agentic AI frameworks are designed to operate with a degree of autonomy, making decisions and taking actions without being explicitly programmed for every scenario.',\n",
              "   'options': ['Autonomy', 'Supervision', 'Determinism', 'Randomness']},\n",
              "  {'question': 'Which of the following is a key application of Agentic AI?',\n",
              "   'answer': 'Complex Decision Making',\n",
              "   'explanation': 'Agentic AI is particularly suited for complex decision-making tasks that require adaptability and the ability to navigate uncertain or dynamic environments.',\n",
              "   'options': ['Simple Automation',\n",
              "    'Complex Decision Making',\n",
              "    'Data Analysis',\n",
              "    'Image Recognition']},\n",
              "  {'question': 'What is a significant trend in the development of Agentic AI frameworks?',\n",
              "   'answer': 'Integration with Reinforcement Learning',\n",
              "   'explanation': 'Recent trends in Agentic AI include the integration with reinforcement learning techniques to enable agents to learn from their environment and improve their decision-making over time.',\n",
              "   'options': ['Integration with Rule-Based Systems',\n",
              "    'Integration with Reinforcement Learning',\n",
              "    'Focus on Explainability',\n",
              "    'Emphasis on Supervised Learning']},\n",
              "  {'question': 'How do Agentic AI systems typically handle uncertainty?',\n",
              "   'answer': 'By Using Probabilistic Models',\n",
              "   'explanation': 'Agentic AI systems often employ probabilistic models to handle uncertainty, allowing them to make informed decisions even when faced with incomplete or ambiguous information.',\n",
              "   'options': ['By Ignoring It',\n",
              "    'By Using Deterministic Models',\n",
              "    'By Using Probabilistic Models',\n",
              "    'By Always Seeking Human Input']},\n",
              "  {'question': 'What is a potential benefit of using Agentic AI in business environments?',\n",
              "   'answer': 'Improved Adaptability to Changing Conditions',\n",
              "   'explanation': 'Agentic AI can offer businesses the ability to adapt more quickly to changing market conditions or unexpected events, thanks to their autonomous decision-making capabilities.',\n",
              "   'options': ['Reduced Need for Human Employees',\n",
              "    'Improved Adaptability to Changing Conditions',\n",
              "    'Simplified IT Infrastructure',\n",
              "    'Guaranteed Predictability of Outcomes']}]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ques.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCRT6Zw7-bK-",
        "outputId": "383afd8d-0303-440c-e85f-a69c39f33a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1:\n",
            "Question: What is the primary characteristic of Agentic AI frameworks?\n",
            "Options:\n",
            "  A. Autonomy\n",
            "  B. Supervision\n",
            "  C. Determinism\n",
            "  D. Randomness\n",
            "\n",
            "Correct Answer: Autonomy\n",
            "Explanation: Agentic AI frameworks are designed to operate with a degree of autonomy, making decisions and taking actions without being explicitly programmed for every scenario.\n",
            "\n",
            "Question 2:\n",
            "Question: Which of the following is a key application of Agentic AI?\n",
            "Options:\n",
            "  A. Simple Automation\n",
            "  B. Complex Decision Making\n",
            "  C. Data Analysis\n",
            "  D. Image Recognition\n",
            "\n",
            "Correct Answer: Complex Decision Making\n",
            "Explanation: Agentic AI is particularly suited for complex decision-making tasks that require adaptability and the ability to navigate uncertain or dynamic environments.\n",
            "\n",
            "Question 3:\n",
            "Question: What is a significant trend in the development of Agentic AI frameworks?\n",
            "Options:\n",
            "  A. Integration with Rule-Based Systems\n",
            "  B. Integration with Reinforcement Learning\n",
            "  C. Focus on Explainability\n",
            "  D. Emphasis on Supervised Learning\n",
            "\n",
            "Correct Answer: Integration with Reinforcement Learning\n",
            "Explanation: Recent trends in Agentic AI include the integration with reinforcement learning techniques to enable agents to learn from their environment and improve their decision-making over time.\n",
            "\n",
            "Question 4:\n",
            "Question: How do Agentic AI systems typically handle uncertainty?\n",
            "Options:\n",
            "  A. By Ignoring It\n",
            "  B. By Using Deterministic Models\n",
            "  C. By Using Probabilistic Models\n",
            "  D. By Always Seeking Human Input\n",
            "\n",
            "Correct Answer: By Using Probabilistic Models\n",
            "Explanation: Agentic AI systems often employ probabilistic models to handle uncertainty, allowing them to make informed decisions even when faced with incomplete or ambiguous information.\n",
            "\n",
            "Question 5:\n",
            "Question: What is a potential benefit of using Agentic AI in business environments?\n",
            "Options:\n",
            "  A. Reduced Need for Human Employees\n",
            "  B. Improved Adaptability to Changing Conditions\n",
            "  C. Simplified IT Infrastructure\n",
            "  D. Guaranteed Predictability of Outcomes\n",
            "\n",
            "Correct Answer: Improved Adaptability to Changing Conditions\n",
            "Explanation: Agentic AI can offer businesses the ability to adapt more quickly to changing market conditions or unexpected events, thanks to their autonomous decision-making capabilities.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Questions Using URL -- Multiple Choice"
      ],
      "metadata": {
        "id": "IbpEX0XEZA9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = Educhain(Nvidia_config)\n",
        "\n",
        "\n",
        "url_list = client.qna_engine.generate_questions_from_data(\n",
        "    source=\"https://www.buildfastwithai.com/genai-course\",\n",
        "    source_type=\"url\",\n",
        "    num=10,\n",
        "    question_type=\"Multiple Choice\",\n",
        "    difficulty_level=\"Intermediate\",\n",
        "    custom_instructions= \"Ask questions only about Satvik\"\n",
        "\n",
        ")\n",
        "\n",
        "url_list.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxzxVqMpA83c",
        "outputId": "4266b48f-059f-45d2-b2f6-3bb09c9875a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1:\n",
            "Question: What is Satvik's educational background?\n",
            "Options:\n",
            "  A. Bachelor's degree from IIT Delhi\n",
            "  B. Master's degree from IIT Delhi\n",
            "  C. Bachelor's and Master's degrees from IIT Delhi\n",
            "  D. PhD from IIT Delhi\n",
            "\n",
            "Correct Answer: Bachelor's and Master's degrees from IIT Delhi\n",
            "Explanation: Satvik is described as having Bachelor's and Master's degrees from IIT Delhi, indicating his educational background is rooted in a prestigious institution known for its academic excellence in fields like engineering and technology.\n",
            "\n",
            "Question 2:\n",
            "Question: What is Satvik's experience in teaching?\n",
            "Options:\n",
            "  A. Taught over 1,000 students\n",
            "  B. Taught over 5,000 students\n",
            "  C. Taught over 10,000 students\n",
            "  D. Taught over 15,000 students\n",
            "\n",
            "Correct Answer: Taught over 15,000 students\n",
            "Explanation: Satvik has experience teaching over 15,000 students, showcasing his extensive background in education and his ability to impart knowledge to a large number of individuals.\n",
            "\n",
            "Question 3:\n",
            "Question: What is Satvik's profession?\n",
            "Options:\n",
            "  A. Data Scientist\n",
            "  B. AI Researcher\n",
            "  C. Founder of Build Fast with AI\n",
            "  D. Product Manager\n",
            "\n",
            "Correct Answer: Founder of Build Fast with AI\n",
            "Explanation: Satvik is identified as the founder of Build Fast with AI, highlighting his role as an entrepreneur and educator in the field of Artificial Intelligence.\n",
            "\n",
            "Question 4:\n",
            "Question: Who is Satvik?\n",
            "Options:\n",
            "  A. An IIT Delhi alumnus and AI expert\n",
            "  B. A Stanford University alumnus and AI expert\n",
            "  C. A Harvard University alumnus and AI expert\n",
            "  D. A MIT alumnus and AI expert\n",
            "\n",
            "Correct Answer: An IIT Delhi alumnus and AI expert\n",
            "Explanation: Satvik is described as an alumnus of IIT Delhi and an expert in AI, underscoring his credibility and expertise in the field of Artificial Intelligence.\n",
            "\n",
            "Question 5:\n",
            "Question: What companies has Satvik collaborated with?\n",
            "Options:\n",
            "  A. Google, Microsoft, and BCG\n",
            "  B. Amazon, Facebook, and Apple\n",
            "  C. Google, Amazon, and Microsoft\n",
            "  D. Microsoft, BCG, and TCS\n",
            "\n",
            "Correct Answer: Google, Microsoft, and BCG\n",
            "Explanation: Satvik has collaborated with tech giants like Google, Microsoft, and BCG, indicating his professional involvement with major industry players.\n",
            "\n",
            "Question 6:\n",
            "Question: How many events has Satvik collaborated on?\n",
            "Options:\n",
            "  A. 50+ events\n",
            "  B. 100+ events\n",
            "  C. 150+ events\n",
            "  D. 200+ events\n",
            "\n",
            "Correct Answer: 150+ events\n",
            "Explanation: Satvik has collaborated on over 150 events, showcasing his extensive experience and involvement in various professional and educational activities.\n",
            "\n",
            "Question 7:\n",
            "Question: What is Satvik's approach to teaching?\n",
            "Options:\n",
            "  A. Theoretical approach\n",
            "  B. Practical approach\n",
            "  C. Hybrid approach\n",
            "  D. Case study approach\n",
            "\n",
            "Correct Answer: Practical approach\n",
            "Explanation: Satvik is known for his practical approach to teaching, enabling participants to translate their knowledge into actionable skills for real-world success.\n",
            "\n",
            "Question 8:\n",
            "Question: What is Satvik's role in Build Fast with AI?\n",
            "Options:\n",
            "  A. Founder\n",
            "  B. CEO\n",
            "  C. CTO\n",
            "  D. Product Manager\n",
            "\n",
            "Correct Answer: Founder\n",
            "Explanation: Satvik is the founder of Build Fast with AI, highlighting his leadership role in the organization.\n",
            "\n",
            "Question 9:\n",
            "Question: How would you describe Satvik's teaching style?\n",
            "Options:\n",
            "  A. Patient, conscientious, and well-intentioned\n",
            "  B. Strict and demanding\n",
            "  C. Lenient and casual\n",
            "  D. Theoretical and complex\n",
            "\n",
            "Correct Answer: Patient, conscientious, and well-intentioned\n",
            "Explanation: Satvik is described as a patient, conscientious, and well-intentioned teacher, indicating his supportive and effective teaching methodology.\n",
            "\n",
            "Question 10:\n",
            "Question: What is Satvik's contact email?\n",
            "Options:\n",
            "  A. satvik@paramkusham.com\n",
            "  B. satvik@buildfastwithai.com\n",
            "  C. satvik.ai@buildfast.com\n",
            "  D. sat\n",
            "\n",
            "Correct Answer: satvik@buildfastwithai.com\n",
            "Explanation: Satvik's contact email is satvik@buildfastwithai.com, providing a direct means of communication for inquiries or further information.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Generate Questions Using URL -- Fill in the Blank"
      ],
      "metadata": {
        "id": "S5UWqxCDM8i7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = Educhain(Nvidia_config)\n",
        "\n",
        "\n",
        "url_list = client.qna_engine.generate_questions_from_data(\n",
        "    source=\"https://www.buildfastwithai.com/genai-course\",\n",
        "    source_type=\"url\",\n",
        "    num=10,\n",
        "    question_type=\"Fill in the Blank\",\n",
        "    difficulty_level=\"Intermediate\",\n",
        "    custom_instructions= \"Ask questions only about Satvik\"\n",
        "\n",
        ")\n",
        "\n",
        "url_list.show()"
      ],
      "metadata": {
        "id": "CYNQJKphM8Um",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfcc6a34-15a4-4218-a9b4-7c6de97ed3b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1:\n",
            "Question: Satvik, the founder of Build Fast with AI, has a background from which prestigious institution?\n",
            "Answer: IIT Delhi\n",
            "Explanation: Satvik is mentioned as an IIT Delhi alumnus.\n",
            "\n",
            "Word to fill: IIT Delhi\n",
            "\n",
            "Question 2:\n",
            "Question: What is Satvik's educational background?\n",
            "Answer: Bachelor's and Master's degrees from IIT Delhi\n",
            "Explanation: It is mentioned that Satvik has Bachelor's and Master's degrees from IIT Delhi.\n",
            "\n",
            "Word to fill: Bachelor's and Master's degrees from IIT Delhi\n",
            "\n",
            "Question 3:\n",
            "Question: How many students has Satvik taught?\n",
            "Answer: 15,000+\n",
            "Explanation: It is stated that Satvik has experience teaching over 15,000 students.\n",
            "\n",
            "Word to fill: 15,000+\n",
            "\n",
            "Question 4:\n",
            "Question: What is Satvik's role in the company Build Fast with AI?\n",
            "Answer: Founder\n",
            "Explanation: Satvik is referred to as the founder of Build Fast with AI.\n",
            "\n",
            "Word to fill: Founder\n",
            "\n",
            "Question 5:\n",
            "Question: Satvik has collaborated with tech giants like _______, Microsoft, and BCG for over 150+ events.\n",
            "Answer: Google\n",
            "Explanation: It is mentioned that Satvik has collaborated with tech giants like Google, Microsoft, and BCG.\n",
            "\n",
            "Word to fill: Google\n",
            "\n",
            "Question 6:\n",
            "Question: Satvik's teaching approach is described as _______.\n",
            "Answer: practical\n",
            "Explanation: It is stated that Satvik believes in a practical approach.\n",
            "\n",
            "Word to fill: practical\n",
            "\n",
            "Question 7:\n",
            "Question: What is Satvik's profession?\n",
            "Answer: AI expert\n",
            "Explanation: Satvik is described as an AI expert.\n",
            "\n",
            "Word to fill: AI expert\n",
            "\n",
            "Question 8:\n",
            "Question: Satvik can be contacted at _______ for further queries.\n",
            "Answer: satvik@buildfastwithai.com\n",
            "Explanation: The email address satvik@buildfastwithai.com is provided for further queries.\n",
            "\n",
            "Word to fill: satvik@buildfastwithai.com\n",
            "\n",
            "Question 9:\n",
            "Question: Satvik has worked with _______ companies for various events.\n",
            "Answer: 150+\n",
            "Explanation: It is mentioned that Satvik has collaborated with tech giants for over 150+ events.\n",
            "\n",
            "Word to fill: 150+\n",
            "\n",
            "Question 10:\n",
            "Question: Satvik's expertise is in the field of _______ and machine learning.\n",
            "Answer: data science\n",
            "Explanation: It is stated that Satvik offers top-tier expertise in data science and machine learning.\n",
            "\n",
            "Word to fill: data science\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Generate Questions Using URL - Short Answer"
      ],
      "metadata": {
        "id": "JhSsWBQhNLuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = Educhain(Nvidia_config)\n",
        "\n",
        "\n",
        "url_list = client.qna_engine.generate_questions_from_data(\n",
        "    source=\"https://www.buildfastwithai.com/genai-course\",\n",
        "    source_type=\"url\",\n",
        "    num=10,\n",
        "    question_type=\"Short Answer\",\n",
        "    difficulty_level=\"Intermediate\",\n",
        "    custom_instructions= \"Ask questions only about Satvik\"\n",
        "\n",
        ")\n",
        "\n",
        "url_list.show()"
      ],
      "metadata": {
        "id": "b9zs5fS0NJtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc277d9-a818-4c38-9ebe-f8948a561fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1:\n",
            "Question: What is Satvik's educational background?\n",
            "Answer: Satvik has Bachelor's and Master's degrees from IIT Delhi.\n",
            "Explanation: Satvik is described as an IIT Delhi alumnus, indicating he has a strong educational background in a relevant field, likely related to AI or technology.\n",
            "\n",
            "Keywords: Satvik, IIT Delhi, education\n",
            "\n",
            "Question 2:\n",
            "Question: What is Satvik's experience in teaching?\n",
            "Answer: Satvik has experience teaching over 15,000 students.\n",
            "Explanation: Satvik has taught a large number of students, indicating his expertise and ability to convey complex concepts to a wide audience.\n",
            "\n",
            "Keywords: Satvik, teaching experience, students\n",
            "\n",
            "Question 3:\n",
            "Question: What companies has Satvik collaborated with?\n",
            "Answer: Satvik has collaborated with tech giants like Google, Microsoft, and BCG.\n",
            "Explanation: Satvik's collaborations with major tech companies suggest he has significant industry experience and insights.\n",
            "\n",
            "Keywords: Satvik, Google, Microsoft, BCG, collaborations\n",
            "\n",
            "Question 4:\n",
            "Question: What is Satvik's role in Build Fast with AI?\n",
            "Answer: Satvik is the founder of Build Fast with AI.\n",
            "Explanation: As the founder, Satvik is likely instrumental in shaping the direction and content of the bootcamp and other initiatives offered by Build Fast with AI.\n",
            "\n",
            "Keywords: Satvik, Build Fast with AI, founder\n",
            "\n",
            "Question 5:\n",
            "Question: How would you describe Satvik's teaching style?\n",
            "Answer: Satvik is described as a patient, conscientious, and well-intentioned teacher.\n",
            "Explanation: Testimonials from students highlight Satvik's positive teaching qualities, indicating he is effective at explaining complex concepts.\n",
            "\n",
            "Keywords: Satvik, teaching style, patient\n",
            "\n",
            "Question 6:\n",
            "Question: What is Satvik's approach to teaching Generative AI?\n",
            "Answer: Satvik believes in a practical approach, enabling participants to translate their knowledge into actionable skills.\n",
            "Explanation: Satvik's practical approach suggests that his teaching focuses on hands-on experience and real-world applications.\n",
            "\n",
            "Keywords: Satvik, practical approach, Generative AI\n",
            "\n",
            "Question 7:\n",
            "Question: How many events has Satvik provided consulting for?\n",
            "Answer: Satvik has provided consulting for over 150 events.\n",
            "Explanation: The number of events Satvik has consulted for indicates his extensive experience and expertise in his field.\n",
            "\n",
            "Keywords: Satvik, consulting, events\n",
            "\n",
            "Question 8:\n",
            "Question: What kind of expertise does Satvik offer?\n",
            "Answer: Satvik offers top-tier expertise in data science and machine learning.\n",
            "Explanation: Satvik's background and experience make him an expert in areas relevant to the bootcamp's focus on Generative AI.\n",
            "\n",
            "Keywords: Satvik, data science, machine learning, expertise\n",
            "\n",
            "Question 9:\n",
            "Question: Why do students recommend Satvik's course?\n",
            "Answer: Students recommend the course due to Satvik's clear explanations and the practical, hands-on experience it provides.\n",
            "Explanation: Testimonials suggest that Satvik's teaching methods and the course structure are highly regarded by his students.\n",
            "\n",
            "Keywords: Satvik, course recommendation, clear explanations\n",
            "\n",
            "Question 10:\n",
            "Question: How can you contact Satvik or his team for further queries?\n",
            "Answer: You can contact Satvik or his team via email at satvik@buildfastwithai.com.\n",
            "Explanation: The provided email address is a direct contact method for inquiries about the bootcamp or other services offered by Build Fast with AI.\n",
            "\n",
            "Keywords: Satvik, contact email, queries\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Generate Math Questions"
      ],
      "metadata": {
        "id": "7InJHPCWTR7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = Educhain(Nvidia_config)\n",
        "maths_ques = client.qna_engine.generate_mcq_math(topic = \"Addition Subtractions\" , num = 5, custom_instruction = \"Include questions with demicals\")\n",
        "maths_ques.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w98kT1LIR6Ij",
        "outputId": "3542c648-e7ea-45b9-b8d3-ca9aa7bc83e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "What is the sum of 456 and 279?\u001b[32;1m\u001b[1;3mTo solve this problem, we need to translate the given math problem into a Python expression that can be executed using the numexpr library.\n",
            "\n",
            "\n",
            "## Step 1\n",
            "The problem asks for the sum of 456 and 279. This can be represented mathematically as 456 + 279.\n",
            "\n",
            "## Step 2\n",
            "To execute this using numexpr, we need to express it as a string that represents a valid Python expression. Therefore, the expression remains \"456 + 279\".\n",
            "\n",
            "## Step 3\n",
            "Now, we use numexpr.evaluate to compute the result of the expression.\n",
            "\n",
            "The code to be executed is:\n",
            "```text\n",
            "456 + 279\n",
            "```\n",
            "...numexpr.evaluate(\"456 + 279\")...\n",
            "\n",
            "## Step 4\n",
            "Running this code will give us the sum.\n",
            "\n",
            "\u001b[0mLLMMathChain failed to answer: unknown format from LLM: To solve this problem, we need to translate the given math problem into a Python expression that can be executed using the numexpr library.\n",
            "\n",
            "\n",
            "## Step 1\n",
            "The problem asks for the sum of 456 and 279. This can be represented mathematically as 456 + 279.\n",
            "\n",
            "## Step 2\n",
            "To execute this using numexpr, we need to express it as a string that represents a valid Python expression. Therefore, the expression remains \"456 + 279\".\n",
            "\n",
            "## Step 3\n",
            "Now, we use numexpr.evaluate to compute the result of the expression.\n",
            "\n",
            "The code to be executed is:\n",
            "```text\n",
            "456 + 279\n",
            "```\n",
            "...numexpr.evaluate(\"456 + 279\")...\n",
            "\n",
            "## Step 4\n",
            "Running this code will give us the sum.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "If you have 750 apples and you give away 372, how many apples do you have left?\u001b[32;1m\u001b[1;3mTo solve this problem, we need to subtract the number of apples given away from the initial number of apples.\n",
            "\n",
            "```text\n",
            "750 - 372\n",
            "```\n",
            "\n",
            "We can use Python's numexpr library to evaluate this expression.\n",
            "\n",
            "...numexpr.evaluate(\"750 - 372\")...\n",
            "\n",
            "\u001b[0mLLMMathChain failed to answer: unknown format from LLM: To solve this problem, we need to subtract the number of apples given away from the initial number of apples.\n",
            "\n",
            "```text\n",
            "750 - 372\n",
            "```\n",
            "\n",
            "We can use Python's numexpr library to evaluate this expression.\n",
            "\n",
            "...numexpr.evaluate(\"750 - 372\")...\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "What is 937 minus 459?\u001b[32;1m\u001b[1;3mTo solve the given problem, we first need to translate the question into a mathematical expression that can be evaluated.\n",
            "\n",
            "Question: What is 937 minus 459?\n",
            "```text\n",
            "937 - 459\n",
            "```\n",
            "We will use Python's numexpr library to evaluate this expression.\n",
            "\n",
            "...numexpr.evaluate(\"937 - 459\")...\n",
            "\u001b[0mLLMMathChain failed to answer: unknown format from LLM: To solve the given problem, we first need to translate the question into a mathematical expression that can be evaluated.\n",
            "\n",
            "Question: What is 937 minus 459?\n",
            "```text\n",
            "937 - 459\n",
            "```\n",
            "We will use Python's numexpr library to evaluate this expression.\n",
            "\n",
            "...numexpr.evaluate(\"937 - 459\")...\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "A store has 275 shirts in stock. They receive a new shipment of 138 shirts. How many shirts does the store have now?\u001b[32;1m\u001b[1;3mTo solve this problem, we need to add the number of shirts the store initially had in stock to the number of shirts they received in the new shipment.\n",
            "\n",
            "The initial number of shirts is 275, and the number of shirts received is 138. So, the total number of shirts is 275 + 138.\n",
            "\n",
            "```text\n",
            "275 + 138\n",
            "```\n",
            "\n",
            "To execute this using Python's numexpr library, we use the following code:\n",
            "...numexpr.evaluate(\"275 + 138\")...\n",
            "\n",
            "\u001b[0mLLMMathChain failed to answer: unknown format from LLM: To solve this problem, we need to add the number of shirts the store initially had in stock to the number of shirts they received in the new shipment.\n",
            "\n",
            "The initial number of shirts is 275, and the number of shirts received is 138. So, the total number of shirts is 275 + 138.\n",
            "\n",
            "```text\n",
            "275 + 138\n",
            "```\n",
            "\n",
            "To execute this using Python's numexpr library, we use the following code:\n",
            "...numexpr.evaluate(\"275 + 138\")...\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "What is 654 plus 287?\u001b[32;1m\u001b[1;3mTo solve this problem, we need to translate the given math problem into a Python expression that can be executed using the numexpr library.\n",
            "\n",
            "\n",
            "## Step 1: Understand the problem and identify the mathematical operation needed.\n",
            "The problem asks us to find the sum of 654 and 287.\n",
            "\n",
            "## Step 2: Translate the math problem into a Python expression.\n",
            "The mathematical operation required is addition, so the expression will be `654 + 287`.\n",
            "\n",
            "## Step 3: Use numexpr to evaluate the expression.\n",
            "We will use `numexpr.evaluate(\"654 + 287\")` to compute the result.\n",
            "\n",
            "## Step 4: Provide the code and its output in the required format.\n",
            "```text\n",
            "654 + 287\n",
            "```\n",
            "...numexpr.evaluate(\"654 + 287\")...\n",
            "\u001b[0mLLMMathChain failed to answer: unknown format from LLM: To solve this problem, we need to translate the given math problem into a Python expression that can be executed using the numexpr library.\n",
            "\n",
            "\n",
            "## Step 1: Understand the problem and identify the mathematical operation needed.\n",
            "The problem asks us to find the sum of 654 and 287.\n",
            "\n",
            "## Step 2: Translate the math problem into a Python expression.\n",
            "The mathematical operation required is addition, so the expression will be `654 + 287`.\n",
            "\n",
            "## Step 3: Use numexpr to evaluate the expression.\n",
            "We will use `numexpr.evaluate(\"654 + 287\")` to compute the result.\n",
            "\n",
            "## Step 4: Provide the code and its output in the required format.\n",
            "```text\n",
            "654 + 287\n",
            "```\n",
            "...numexpr.evaluate(\"654 + 287\")...\n",
            "Question 1:\n",
            "Question: What is the sum of 456 and 279?\n",
            "  A. Unable to compute (Correct)\n",
            "  B. N/A \n",
            "  C. N/A \n",
            "  D. N/A \n",
            "Explanation: To find the sum, we add 456 and 279. First, we add the hundreds: 400 + 200 = 600. Then, we add the tens: 50 + 70 = 120. Finally, we add the ones: 6 + 9 = 15. Adding these together: 600 + 120 + 15 = 735.\n",
            "\n",
            "Math solution: Unable to compute.\n",
            "\n",
            "Question 2:\n",
            "Question: If you have 750 apples and you give away 372, how many apples do you have left?\n",
            "  A. Unable to compute (Correct)\n",
            "  B. N/A \n",
            "  C. N/A \n",
            "  D. N/A \n",
            "Explanation: To find out how many apples are left, we subtract the number given away from the total. So, 750 - 372. First, subtract the hundreds: 700 - 300 = 400. Then, the tens: 50 - 70 = -20. And the ones: 0 - 2 = -2. Combining these: 400 - 20 - 2 = 378.\n",
            "\n",
            "Math solution: Unable to compute.\n",
            "\n",
            "Question 3:\n",
            "Question: What is 937 minus 459?\n",
            "  A. Unable to compute (Correct)\n",
            "  B. N/A \n",
            "  C. N/A \n",
            "  D. N/A \n",
            "Explanation: To find the difference, we subtract 459 from 937. First, subtract the hundreds: 900 - 400 = 500. Then, the tens: 30 - 50 = -20. And the ones: 7 - 9 = -2. Combining these: 500 - 20 - 2 = 478.\n",
            "\n",
            "Math solution: Unable to compute.\n",
            "\n",
            "Question 4:\n",
            "Question: A store has 275 shirts in stock. They receive a new shipment of 138 shirts. How many shirts does the store have now?\n",
            "  A. Unable to compute (Correct)\n",
            "  B. N/A \n",
            "  C. N/A \n",
            "  D. N/A \n",
            "Explanation: To find the total number of shirts, we add the initial stock to the new shipment. So, 275 + 138. First, add the hundreds: 200 + 100 = 300. Then, the tens: 70 + 30 = 100. And the ones: 5 + 8 = 13. Adding these together: 300 + 100 + 13 = 413.\n",
            "\n",
            "Math solution: Unable to compute.\n",
            "\n",
            "Question 5:\n",
            "Question: What is 654 plus 287?\n",
            "  A. Unable to compute (Correct)\n",
            "  B. N/A \n",
            "  C. N/A \n",
            "  D. N/A \n",
            "Explanation: To find the sum, we add 654 and 287. First, add the hundreds: 600 + 200 = 800. Then, the tens: 50 + 80 = 130. And the ones: 4 + 7 = 11. Adding these together: 800 + 130 + 11 = 941.\n",
            "\n",
            "Math solution: Unable to compute.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}